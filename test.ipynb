{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "import gzip\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from scipy.stats import multinomial\n",
    "dmultinom = multinomial.pmf\n",
    "\n",
    " \n",
    "\n",
    "def shrink_depth(depth, threshold = 60):\n",
    "\n",
    "    k = threshold - np.sqrt(threshold)\n",
    "\n",
    "    depth[depth > threshold] = np.round(np.sqrt(depth[depth > threshold]) + k)\n",
    "    return depth\n",
    "\n",
    "\n",
    "# mutation rate\n",
    "pm = 1/1000/3\n",
    "\n",
    "# error rate\n",
    "# in oocyte samples, error rate is set triple\n",
    "# pe = 1/100/3\n",
    "pe = 3/100/3\n",
    "\n",
    "# total mis rate\n",
    "p = pm + pe\n",
    "\n",
    "# methylation rate/proportion \n",
    "pr_cg = 0.6        # CG content\n",
    "pr_ncg = 1/100     # non-CG content\n",
    "\n",
    "\n",
    "# transition prob of haploidy, likelihood\n",
    "\n",
    "def transA(pr):\n",
    "    return (1-3*pm-3*pe, 2*pm-pm*pr+pe, pm*pr+pe, pm+pe)\n",
    "def transT(pr):\n",
    "    return (pm+pe, 1-2*pm-pm*pr-3*pe, pm*pr+pe, pm+pe)\n",
    "def transC(pr):\n",
    "    return (pm+pe, pm+pe+(1-3*pm-3*pe)*(1-pr), (1-3*pm-3*pe)*pr, pm+pe)\n",
    "def transG(pr):\n",
    "    return (pm+pe, 2*pm-pm*pr+pe, pm*pr+pe, 1-3*pm-3*pe)\n",
    "\n",
    "PAs = {'CG': np.array(transA(pr_cg)), 'CH': np.array(transA(pr_ncg))}\n",
    "PTs = {'CG': np.array(transT(pr_cg)), 'CH': np.array(transT(pr_ncg))}\n",
    "PCs = {'CG': np.array(transC(pr_cg)), 'CH': np.array(transC(pr_ncg))}\n",
    "PGs = {'CG': np.array(transG(pr_cg)), 'CH': np.array(transG(pr_ncg))}\n",
    "\n",
    "zeros4 = np.array([0]*4)\n",
    "\n",
    "# Wastson strand\n",
    "\n",
    "P_AWs = {'CG': np.append(transA(pr_cg), zeros4), \n",
    "        'CH': np.append(transA(pr_ncg), zeros4)}\n",
    "P_TWs = {'CG': np.append(transT(pr_cg), zeros4), \n",
    "        'CH': np.append(transT(pr_ncg), zeros4)}\n",
    "P_CWs = {'CG': np.append(transC(pr_cg), zeros4), \n",
    "        'CH': np.append(transC(pr_ncg), zeros4)}\n",
    "P_GWs = {'CG': np.append(transG(pr_cg), zeros4), \n",
    "        'CH': np.append(transG(pr_ncg), zeros4)}\n",
    "\n",
    "# Crick strand\n",
    "\n",
    "P_ACs = {'CG': np.append(zeros4, transA(pr_cg)), \n",
    "        'CH': np.append(zeros4, transA(pr_ncg))}\n",
    "P_TCs = {'CG': np.append(zeros4, transT(pr_cg)), \n",
    "        'CH': np.append(zeros4, transT(pr_ncg))}\n",
    "P_CCs = {'CG': np.append(zeros4, transC(pr_cg)), \n",
    "        'CH': np.append(zeros4, transC(pr_ncg))}\n",
    "P_GCs = {'CG': np.append(zeros4, transG(pr_cg)), \n",
    "        'CH': np.append(zeros4, transG(pr_ncg))}\n",
    "\n",
    "## log p_i, n_lines X 10 (genotypes)\n",
    "            # [dmultinom(coverage, DP, np.append(PA, PT)/2), # A\n",
    "            #     dmultinom(coverage, DP, np.append(PT, PA)/2), # T\n",
    "            #     dmultinom(coverage, DP, np.append(PC, PG)/2), # C\n",
    "            #     dmultinom(coverage, DP, np.append(PG, PC)/2), # G\n",
    "            #     dmultinom(coverage, DP, np.append(PA+PC, PT+PG)/4), # AC\n",
    "            #     dmultinom(coverage, DP, np.append(PA+PG, PT+PC)/4), # AG\n",
    "            #     dmultinom(coverage, DP, np.append(PA+PT, PT+PA)/4), # AT\n",
    "            #     dmultinom(coverage, DP, np.append(PC+PG, PG+PC)/4), # CG\n",
    "            #     dmultinom(coverage, DP, np.append(PC+PT, PG+PA)/4), # CT\n",
    "            #     dmultinom(coverage, DP, np.append(PG+PT, PC+PA)/4)  # GT\n",
    "def log_likelihood(pattern):\n",
    "    P_AW = P_AWs[pattern]\n",
    "    P_TW = P_TWs[pattern]\n",
    "    P_CW = P_CWs[pattern]\n",
    "    P_GW = P_GWs[pattern]\n",
    "    P_AC = P_ACs[pattern]\n",
    "    P_TC = P_TCs[pattern]\n",
    "    P_CC = P_CCs[pattern]\n",
    "    P_GC = P_GCs[pattern]\n",
    "    \n",
    "    mx = np.log(np.vstack([\n",
    "        (P_AW+P_TC)/2, (P_TW+P_AC)/2, (P_CW+P_GC)/2, (P_GW+P_CC)/2, # A T C G\n",
    "        (P_AW+P_CW+P_TC+P_GC)/4, # AC\n",
    "        (P_AW+P_GW+P_TC+P_CC)/4, # AG\n",
    "        (P_AW+P_TW+P_AC+P_TC)/4, # AT\n",
    "        (P_CW+P_GW+P_CC+P_GC)/4, # CG\n",
    "        (P_CW+P_TW+P_AC+P_GC)/4, # CT\n",
    "        (P_GW+P_TW+P_AC+P_CC)/4  # GT\n",
    "        ], dtype=float).T)\n",
    "    return mx\n",
    "\n",
    "log_p_i = {'CG': log_likelihood('CG'), 'CH': log_likelihood('CH')}\n",
    "\n",
    "\n",
    "\n",
    "# STATUS\n",
    "HOMO = ('A', 'T', 'C', 'G')\n",
    "HETER = ('AC', 'AG', 'AT', 'CG', 'CT', 'GT')\n",
    "STATUS = HOMO + HETER\n",
    "\n",
    "\n",
    "# prior\n",
    "\n",
    "ps = np.array(((1-3*p)**2, p**2, 2*p*(1-3*p)))\n",
    "\n",
    "# 0-based\n",
    "priA = ps[np.array([1,2,2,2,3,3,3,2,2,2]) -1]\n",
    "priT = ps[np.array([2,1,2,2,2,2,3,2,3,3]) -1]\n",
    "priC = ps[np.array([2,2,1,2,3,2,2,3,3,2]) -1]\n",
    "priG = ps[np.array([2,2,2,1,2,3,2,3,2,3]) -1]\n",
    "\n",
    "pris = {'A': priA, 'T': priT, 'C': priC, 'G': priG}\n",
    "\n",
    "## allele frequencies\n",
    "\n",
    "allele_weights = np.array(\n",
    "    (1, 0, 0, 0, 0.5, 0.5, 0.5, 0  , 0  , 0  ,\n",
    "    0, 1, 0, 0, 0,   0  , 0.5, 0  , 0.5, 0.5,\n",
    "    0, 0, 1, 0, 0.5, 0  , 0  , 0.5, 0.5, 0  ,\n",
    "    0, 0, 0, 1, 0  , 0.5, 0  , 0.5, 0  , 0.5\n",
    "    ), \n",
    "    dtype='float32').reshape(4, 10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def writeLine(lines):\n",
    "    global TASKS_IN_QUEUE\n",
    "    TASKS_IN_QUEUE -= 1\n",
    "\n",
    "    for l in lines:\n",
    "        OUT.write(l)\n",
    "\n",
    "def readBatch(IN, BATACH_SIZE = 1000):\n",
    "    i = 0\n",
    "    line_batch = []\n",
    "    while i < BATACH_SIZE:\n",
    "        line = IN.readline().strip()\n",
    "        if line:\n",
    "            line_batch.append(line)\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    return line_batch\n",
    "\n",
    "\n",
    "class LineFile:\n",
    "    def __init__(self, filename: str, batchSize: int):\n",
    "        if filename.endswith(\".gz\") :\n",
    "            self.input = gzip.open(filename, 'rt')\n",
    "        else :\n",
    "            self.input = io.open(filename, 'r')\n",
    "        self.batchSize = batchSize\n",
    "        self.exhausted = False\n",
    "    # def __iter__(self):\n",
    "    #     return self\n",
    "    def __next__(self):\n",
    "        if self.exhausted:\n",
    "            return None\n",
    "        \n",
    "        # number if readed lines \n",
    "        i = 0\n",
    "        lines = []\n",
    "        while (l := self.input.readline().strip()) and (i < self.batchSize):\n",
    "            lines.append(l)\n",
    "            i += 1\n",
    "        if i < self.batchSize:\n",
    "            self.exhausted = True\n",
    "\n",
    "        if i > 0:\n",
    "            return lines\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def close(self):\n",
    "        if not self.input.closed:\n",
    "            self.input.close()\n",
    "\n",
    "class WaitTimeSchimitter:\n",
    "    def __init__(self, thres_u:int, thres_l:int, wtime: float, FLAG_WAIT: str):\n",
    "        self.thres_u = thres_u\n",
    "        self.thres_l = thres_l\n",
    "        self.wtime = wtime\n",
    "        self.FLAG_WAIT = FLAG_WAIT\n",
    "\n",
    "    def setWaitTimeFlag(self, k:int):\n",
    "        if self.FLAG_WAIT == 'upper':\n",
    "            if k < self.thres_l:\n",
    "                self.FLAG_WAIT = 'lower'\n",
    "        elif self.FLAG_WAIT == 'lower':\n",
    "            if k > self.thres_u:\n",
    "                self.FLAG_WAIT = 'upper'\n",
    "\n",
    "    def waitTime(self, k: int):\n",
    "        self.setWaitTimeFlag(k)\n",
    "        if self.FLAG_WAIT == 'upper':\n",
    "            time.sleep(self.wtime)\n",
    "            \n",
    "            print(f'Waiting: {self.FLAG_WAIT}, {k}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "TASKS_IN_QUEUE = 0\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# FLAG_WAIT = 'upper'\n",
    "\n",
    "# start 4 worker processes\n",
    "\n",
    "infile = 'D:/Documents/GitHub/BS-SNV-Caller/data/atcg.simple'\n",
    "# IN = io.open(infile, 'r')\n",
    "\n",
    "# outfile = 'D:/Documents/GitHub/BS-SNV-Caller/data/atcg.half.out6.gz'\n",
    "# OUT = gzip.open(outfile, 'wt')\n",
    "# # OUT = io.open(outfile, 'w+')\n",
    "# # OUT = 'data/out'\n",
    "\n",
    "\n",
    "ATCGfile = LineFile(infile, BATCH_SIZE)\n",
    "\n",
    "args = {'p.value': 1, 'min.coverage': 1, 'shrink.DP': 60}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATCGfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_batch = next(ATCGfile)\n",
    "line_res = [l.split('\\t') for l in line_batch]\n",
    "# for l in line_batch:\n",
    "#     line_res.append(l.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(line_res)\n",
    "\n",
    "BASES = ['A', 'T', 'C', 'G']\n",
    "N_rows, _ = array.shape\n",
    "\n",
    "refs = array[:,1]\n",
    "patterns = array[:,3]\n",
    "reads = array[:,(5,6,7,8, 11,10,13,12)].astype(int) # diff bases in the Crick strand\n",
    "\n",
    "is_CG = patterns == 'CG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mx = np.zeros((N_rows, 10))\n",
    "\n",
    "post_mx[is_CG, :] = reads[is_CG, :] @ log_p_i['CG']\n",
    "post_mx[~is_CG, :] = reads[~is_CG, :] @ log_p_i['CH']\n",
    "\n",
    "post_mx = np.exp(post_mx - np.max(post_mx, axis=1, keepdims=True))\n",
    "\n",
    "# priors\n",
    "\n",
    "prior_mx = np.zeros((N_rows, 10))\n",
    "\n",
    "for ref in BASES:\n",
    "    prior_mx[refs == ref, :] = pris[ref]\n",
    "\n",
    "# post prob and normalization\n",
    "\n",
    "post_mx *= prior_mx\n",
    "post_mx = post_mx / np.sum(post_mx, axis=1, keepdims=True)\n",
    "\n",
    "    \n",
    "# prob of unmutation (same with ref) was\n",
    "# regarded as p.value\n",
    "\n",
    "p_value = np.zeros(N_rows, dtype=float)\n",
    "for i in range(len(BASES)):\n",
    "    I = refs == BASES[i]\n",
    "    p_value[I] = post_mx[I, i]\n",
    "\n",
    "# significant sites\n",
    "\n",
    "i_sig = p_value < args['p.value']\n",
    "\n",
    "# if i_sig.sum() == 0:\n",
    "#     return(None)\n",
    "\n",
    "#  only return singnificant sites\n",
    "\n",
    "p_values = p_value[i_sig]\n",
    "chrs = array[i_sig, 0]\n",
    "poss = array[i_sig, 2]\n",
    "reffs = refs[i_sig]\n",
    "\n",
    "\n",
    "# allele frequencies\n",
    "allele_freq = post_mx[i_sig,:] @ allele_weights.T\n",
    "\n",
    "DP_watson = np.sum(reads[i_sig, :4], axis=1)\n",
    "DP_crick = np.sum(reads[i_sig, 4:8], axis=1)\n",
    "p_homozyte = np.sum(post_mx[i_sig, :4], axis=1)\n",
    "\n",
    "lines_res = []\n",
    "\n",
    "for i in range(i_sig.sum()):\n",
    "    lines_res.append('%s\\t%s\\t%s\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%d\\t%d\\n' % (\n",
    "    chrs[i], poss[i], reffs[i],\n",
    "    p_values[i], p_homozyte[i],\n",
    "    allele_freq[i,0], allele_freq[i,1], allele_freq[i,2], allele_freq[i,3],\n",
    "    DP_watson[i], DP_crick[i]\n",
    "    ))\n",
    "\n",
    "return(lines_res)\n",
    "\n",
    "# pd.DataFrame(post_mx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_SNV_Caller(lines: list, args: dict):\n",
    "    line_res = [l.split('\\t') for l in lines]\n",
    "\n",
    "    array = np.array(line_res)\n",
    "\n",
    "    ## exclude Ns\n",
    "    array = array[array[:,1] != 'N',:]\n",
    "\n",
    "    reads = array[:,(5,6,7,8, 11,10,13,12)].astype(int) # diff bases in the Crick strand\n",
    "\n",
    "    # sqrt-transform read counts\n",
    "    \n",
    "    i = reads > args['shrink.DP']\n",
    "    if i.sum() > 0:\n",
    "        reads[i] = shrink_depth(reads[i], args['shrink.DP'])\n",
    "\n",
    "    # exclude sites of low coverage\n",
    "\n",
    "    i = np.sum(reads, axis=1) < args['min.DP']\n",
    "    if i.sum() > 0:\n",
    "        reads = reads[not i, :]\n",
    "\n",
    "    ## basic vars\n",
    "    \n",
    "    BASES = ['A', 'T', 'C', 'G']\n",
    "    N_rows, _ = array.shape\n",
    "\n",
    "    refs = array[:,1]\n",
    "    patterns = array[:,3]\n",
    "\n",
    "    is_CG = patterns == 'CG'\n",
    "\n",
    "    ## posterior \\prop likelihood (multinomial) \\times prior\n",
    "\n",
    "    post_mx = np.zeros((N_rows, 10))\n",
    "\n",
    "    post_mx[is_CG, :] = reads[is_CG, :] @ log_p_i['CG']\n",
    "    post_mx[np.logical_not(is_CG), :] = reads[np.logical_not(is_CG), :] @ log_p_i['CH']\n",
    "\n",
    "    post_mx = np.exp(post_mx - np.max(post_mx, axis=1, keepdims=True))\n",
    "\n",
    "    # priors\n",
    "\n",
    "    prior_mx = np.zeros((N_rows, 10))\n",
    "\n",
    "    for ref in BASES:\n",
    "        prior_mx[refs == ref, :] = pris[ref]\n",
    "\n",
    "    # post prob and normalization\n",
    "\n",
    "    post_mx *= prior_mx\n",
    "    post_mx = post_mx / np.sum(post_mx, axis=1, keepdims=True)\n",
    "\n",
    "        \n",
    "    # prob of unmutation (same with ref) was\n",
    "    # regarded as p.value\n",
    "\n",
    "    p_value = np.zeros(N_rows, dtype=float)\n",
    "    for i in range(len(BASES)):\n",
    "        I = refs == BASES[i]\n",
    "        p_value[I] = post_mx[I, i]\n",
    "\n",
    "    # significant sites\n",
    "\n",
    "    i_sig = p_value < args['p.value']\n",
    "\n",
    "    if i_sig.sum() == 0:\n",
    "        return(None)\n",
    "\n",
    "    #  only return singnificant sites\n",
    "\n",
    "    p_values = p_value[i_sig]\n",
    "    chrs = array[i_sig, 0]\n",
    "    poss = array[i_sig, 2]\n",
    "    reffs = refs[i_sig]\n",
    "\n",
    "\n",
    "    # allele frequencies\n",
    "    allele_freq = post_mx[i_sig,:] @ allele_weights.T\n",
    "\n",
    "    DP_watson = np.sum(reads[i_sig, :4], axis=1)\n",
    "    DP_crick = np.sum(reads[i_sig, 4:8], axis=1)\n",
    "    p_homozyte = np.sum(post_mx[i_sig, :4], axis=1)\n",
    "\n",
    "    lines_res = []\n",
    "\n",
    "    for i in range(i_sig.sum()):\n",
    "        lines_res.append('%s\\t%s\\t%s\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%d\\t%d\\n' % (\n",
    "        chrs[i], poss[i], reffs[i],\n",
    "        p_values[i], p_homozyte[i],\n",
    "        allele_freq[i,0], allele_freq[i,1], allele_freq[i,2], allele_freq[i,3],\n",
    "        DP_watson[i], DP_crick[i]\n",
    "        ))\n",
    "\n",
    "    return(lines_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\t1023891\\tT\\t9.999998e-01\\t9.999998e-01\\t2.712559e-11\\t9.999999e-01\\t9.762562e-08\\t2.712559e-11\\t12\\t17\\n',\n",
       " '1\\t1023892\\tC\\t9.999998e-01\\t9.999998e-01\\t1.371137e-11\\t9.723202e-08\\t9.999999e-01\\t1.371137e-11\\t13\\t17\\n',\n",
       " '1\\t1023893\\tC\\t9.999996e-01\\t9.999996e-01\\t3.504805e-12\\t1.923189e-07\\t9.999998e-01\\t3.504805e-12\\t16\\t16\\n',\n",
       " '1\\t1023894\\tT\\t9.999996e-01\\t9.999996e-01\\t1.771780e-12\\t9.999998e-01\\t1.933472e-07\\t1.771780e-12\\t17\\t16\\n',\n",
       " '1\\t1023895\\tT\\t9.999996e-01\\t9.999996e-01\\t1.771780e-12\\t9.999998e-01\\t1.933472e-07\\t1.771780e-12\\t17\\t16\\n',\n",
       " '1\\t1023896\\tG\\t9.999998e-01\\t9.999998e-01\\t9.718489e-08\\t1.771090e-12\\t1.771090e-12\\t9.999999e-01\\t17\\t16\\n',\n",
       " '1\\t1023897\\tC\\t1.000000e+00\\t1.000000e+00\\t5.117815e-13\\t5.117815e-13\\t1.000000e+00\\t5.117815e-13\\t19\\t16\\n',\n",
       " '1\\t1023898\\tG\\t1.000000e+00\\t1.000000e+00\\t2.888515e-12\\t2.577904e-13\\t2.577904e-13\\t1.000000e+00\\t20\\t16\\n',\n",
       " '1\\t1023899\\tC\\t9.999996e-01\\t9.999996e-01\\t2.288462e-13\\t1.921946e-07\\t9.999998e-01\\t2.288462e-13\\t20\\t16\\n',\n",
       " '1\\t1023900\\tC\\t9.999996e-01\\t9.999996e-01\\t2.288462e-13\\t1.921946e-07\\t9.999998e-01\\t2.288462e-13\\t20\\t16\\n']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS_SNV_Caller(line_batch, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {'p.value': 1, 'min.DP': 1, 'shrink.DP': 60}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~ is_CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e9/1e6*3/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8235294117647056"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.20/1.36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
